{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#\n",
    "# tests.ipynb \t        (c) Ian Williams, Adnan Khan, Matt McQuinn\n",
    "#     \t\t\t\t    \tianw89@live.com\n",
    "#\n",
    "###################################################################################################\n",
    "\n",
    "# NOTE: Always clear results before checking in a jupyter notebook. This improves diffs.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import convolve\n",
    "import matplotlib.pyplot as plt\n",
    "from testutils import *\n",
    "import pandas as pd\n",
    "import cgmbrush.plots.plotting_routines as makefig\n",
    "\n",
    "from cgmbrush.cgmbrush import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit tests for some basic functions\n",
    "result = halo.Rvir_den(cosmo, 0)\n",
    "print(result)\n",
    "assert (math.isclose(result,38235.05346)), \"Rvir_den(0) gave unexpected value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some test data used below.\n",
    "a = np.zeros((100, 100))\n",
    "a[49][48] = 1\n",
    "a[49][49] = 1\n",
    "a[49][50] = 1\n",
    "a[48][49] = 1\n",
    "a[50][49] = 1\n",
    "\n",
    "a_single_dot =+ np.zeros((30, 30))\n",
    "a_single_dot[14][14] = 1\n",
    "\n",
    "a_with_corner = np.zeros((30, 30))\n",
    "a_with_corner[14][14] = 1\n",
    "a_with_corner[14][15] = 1\n",
    "a_with_corner[14][13] = 1\n",
    "a_with_corner[15][14] = 1\n",
    "a_with_corner[13][14] = 1\n",
    "a_with_corner[1][0] = 1\n",
    "a_with_corner[1][2] = 1\n",
    "a_with_corner[1][1] = 1\n",
    "a_with_corner[2][1] = 1\n",
    "a_with_corner[0][1] = 1\n",
    "\n",
    "b_even = np.zeros((10,10))\n",
    "b_even[4][3] = 1\n",
    "b_even[4][5] = 1\n",
    "b_even[4][4] = 1\n",
    "b_even[3][4] = 1\n",
    "b_even[5][4] = 1\n",
    "\n",
    "b_big = np.zeros((80,80))\n",
    "b_big[39][39] = 1\n",
    "b_big[40][39] = 1\n",
    "b_big[38][39] = 1\n",
    "b_big[39][40] = 1\n",
    "b_big[39][38] = 1\n",
    "\n",
    "b_odd = np.zeros((15,15))\n",
    "b_odd[7][7] = 1\n",
    "b_odd[7][8] = 1\n",
    "b_odd[7][6] = 1\n",
    "b_odd[8][7] = 1\n",
    "b_odd[6][7] = 1\n",
    "\n",
    "b_lumpy = np.zeros((20,20))\n",
    "b_lumpy[11][10] = 0.1154235\n",
    "b_lumpy[10][11] = 0.111363\n",
    "b_lumpy[11][11] = 0.4854334\n",
    "\n",
    "# Resolution 1 equivalent in cgmbrush\n",
    "a_large = np.random.random((1024,1024))\n",
    "b_random = np.random.random((20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof that our convolution implementation is equivalent to what we did before for even sized filters\n",
    "c8 = convolve(a, b_even, mode='wrap') # This is almost what we do today: just same method but using wrap instead of reflect\n",
    "c3 = my_convolve(a, b_even)\n",
    "assert (np.allclose(c8, c3)), \"test failed\"\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 4))\n",
    "axes[0].imshow(a) \n",
    "axes[1].imshow(c3) # hand written version\n",
    "axes[2].imshow(c8) # old vesion, but periodic instead of symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof that our convolution implementation is equivalent to what we did before for odd sized filters\n",
    "c8 = convolve(a, b_odd, mode='wrap') # This is almost what we do today: just same method but using wrap instead of reflect\n",
    "c3 = my_convolve(a, b_odd)\n",
    "assert (np.allclose(c8, c3)), \"test failed\"\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 4))\n",
    "axes[0].imshow(a) \n",
    "axes[1].imshow(c3) # hand written version\n",
    "axes[2].imshow(c8) # old vesion, but periodic instead of symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof that our convolution implementation is equivalent to what we did before for large masks\n",
    "c8 = convolve(a, b_big, mode='wrap') # This is almost what we do today: just same method but using wrap instead of reflect\n",
    "c3 = my_convolve(a, b_big)\n",
    "assert (np.allclose(c8, c3)), \"test failed\"\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 4))\n",
    "axes[0].imshow(a) \n",
    "axes[1].imshow(c3) # hand written version\n",
    "axes[2].imshow(c8) # old vesion, but periodic instead of symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof that our convolution implementation is equivalent to what we did before when stuff is near the corner\n",
    "c8 = convolve(a_single_dot, b_even, mode='wrap') # This is almost what we do today: just same method but using wrap instead of reflect\n",
    "c3 = my_convolve(a_single_dot, b_even)\n",
    "assert (np.allclose(c8, c3)), \"test failed\"\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 4))\n",
    "axes[0].imshow(a_single_dot) \n",
    "axes[1].imshow(c3) # hand written version\n",
    "axes[2].imshow(c8) # old vesion, but periodic instead of symmetric\n",
    "\n",
    "assert (not np.allclose(np.zeros((30,30)), c3)), \"should be false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof that our convolution implementation is equivalent to what we did before when stuff is near the corner\n",
    "c8 = convolve(a_with_corner, b_even, mode='wrap') # This is almost what we do today: just same method but using wrap instead of reflect\n",
    "c3 = my_convolve(a_with_corner, b_even)\n",
    "assert (np.allclose(c8, c3)), \"test failed\"\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 4))\n",
    "axes[0].imshow(a_with_corner) \n",
    "axes[1].imshow(c3) # hand written version\n",
    "axes[2].imshow(c8) # old vesion, but periodic instead of symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof that our convolution implementation is equivalent to what we did before when stuff both imputs are random values\n",
    "c8 = convolve(a_large, b_random, mode='wrap') # This is almost what we do today: just same method but using wrap instead of reflect\n",
    "c3 = my_convolve(a_large, b_random)\n",
    "assert (np.allclose(c8, c3)), \"test failed\"\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 4))\n",
    "axes[0].imshow(a_large) \n",
    "axes[1].imshow(c3) # hand written version\n",
    "axes[2].imshow(c8) # old vesion, but periodic instead of symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof that my implementation is equivalent to what we did before for lumpy mask\n",
    "c8 = convolve(a_large, b_lumpy, mode='wrap') # This is almost what we do today: just same method but using wrap instead of reflect\n",
    "c3 = my_convolve(a_large, b_lumpy)\n",
    "assert (np.allclose(c8, c3)), \"test failed\"\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15, 4))\n",
    "axes[0].imshow(a_large) \n",
    "axes[1].imshow(c3) # hand written version\n",
    "axes[2].imshow(c8) # old vesion, but periodic instead of symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('data/problem halos.npy', allow_pickle=True)\n",
    "b = np.load('data/problem mask.npy', allow_pickle=True)\n",
    "\n",
    "c8 = convolve(a, b, mode='wrap')\n",
    "c3 = my_convolve(a, b)\n",
    "assert (np.allclose(c8, c3)), \"test failed\"\n",
    "\n",
    "fig, axes = plt.subplots(1,4,figsize=(18, 4))\n",
    "pos = axes[0].imshow(a) \n",
    "fig.colorbar(pos, ax=axes[0])\n",
    "pos = axes[1].imshow(c3) # hand written version\n",
    "fig.colorbar(pos, ax=axes[1])\n",
    "pos = axes[2].imshow(c8) # old vesion, but periodic instead of symmetric\n",
    "fig.colorbar(pos, ax=axes[2])\n",
    "pos = axes[3].imshow(c8 - c3) # delta between them\n",
    "fig.colorbar(pos, ax=axes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('data/problem 2 halos.npy', allow_pickle=True)\n",
    "b = np.load('data/problem 2 mask.npy', allow_pickle=True)\n",
    "\n",
    "c8 = convolve(a, b, mode='wrap') \n",
    "c3 = my_convolve(a, b)\n",
    "\n",
    "fig, axes = plt.subplots(1,4,figsize=(18, 4))\n",
    "pos = axes[0].imshow(a) \n",
    "fig.colorbar(pos, ax=axes[0])\n",
    "pos = axes[1].imshow(c3) # hand written version\n",
    "fig.colorbar(pos, ax=axes[1])\n",
    "pos = axes[2].imshow(c8) # old vesion, but periodic instead of symmetric\n",
    "fig.colorbar(pos, ax=axes[2])\n",
    "pos = axes[3].imshow(c8 - c3) # delta between them\n",
    "fig.colorbar(pos, ax=axes[3])\n",
    "\n",
    "# Fails at 1e-08 level (default) absolute tolerance, but that's ok\n",
    "assert (np.allclose(c8, c3, atol=1e-07)), \"test failed\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('data/problem 3 halos.npy', allow_pickle=True)\n",
    "b = np.load('data/problem 3 mask.npy', allow_pickle=True)\n",
    "\n",
    "c8 = convolve(a, b, mode='wrap')\n",
    "c3 = my_convolve(a, b)\n",
    "\n",
    "fig, axes = plt.subplots(1,4,figsize=(18, 4))\n",
    "pos = axes[0].imshow(a) \n",
    "fig.colorbar(pos, ax=axes[0])\n",
    "pos = axes[1].imshow(c3) # hand written version\n",
    "fig.colorbar(pos, ax=axes[1])\n",
    "pos = axes[2].imshow(c8) # old vesion, but periodic instead of symmetric\n",
    "fig.colorbar(pos, ax=axes[2])\n",
    "pos = axes[3].imshow(c8 - c3) # delta between them\n",
    "fig.colorbar(pos, ax=axes[3])\n",
    "\n",
    "# Fails at 1e-08 level (default) absolute tolerance, but it's only because all the numbers are larger in this example\n",
    "assert (np.allclose(c8, c3, atol=1e-03)), \"test failed\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Testing for end to end convolutions\n",
    "# The idea here is to baseline some so one can ensure that future changes to the code do not change the results (up to a tolerance)\n",
    "REWRITE_BASELINES = False\n",
    "filename_header = \"baseline_e2e_%s\"\n",
    "profiles = [TophatProfile(), SphericalTophatProfile(), NFWProfile(), FireProfile(), PrecipitationProfile(), MassDependentProfile(SphericalTophatProfile(rvir_factor=2), NFWProfile(), 1e12)]\n",
    "\n",
    "for profile in profiles:\n",
    "    print(\"Profile: %s\" % profile.name)\n",
    "    config = Configuration(profile, 1, resolution=1, provider=BolshoiProvider())\n",
    "    config.min_mass = 10**10\n",
    "    config.max_mass = 10**14.5\n",
    "    config.log_bins = 30\n",
    "    config.run()\n",
    "    check_validity(config)\n",
    "\n",
    "    if REWRITE_BASELINES:\n",
    "        saveResults(filename_header % profile.name, **config.results, folder=TEST_DIR)\n",
    "    else:\n",
    "        baseline = force_load_npz(filename_header % profile.name, folder=TEST_DIR)\n",
    "\n",
    "        # Most important: test the final density grid values\n",
    "        for i in range(len(config.RS_array)):\n",
    "            print(\"summed field ratio =\", np.sum(config.get_final_field())/np.sum(baseline['final_density_field']))\n",
    "            test_pass = np.allclose(config.get_final_field()[i], baseline['final_density_field'][i], rtol=1e-12, atol=1e-3)\n",
    "            if not test_pass:\n",
    "                plot_grid_comparison(config.get_final_field()[i], baseline['final_density_field'][i])\n",
    "                raise Exception(\"Test failed for profile '{}'. Final density grid has changed at redshift {}.\".format(profile.name, config.RS_array[i]))\n",
    "        \n",
    "        # Test all the addition masks across all mass bins\n",
    "        test_pass = np.allclose(config.get_addition_masks(), baseline['add_masks'], rtol=1e-12, atol=1e-3)\n",
    "        if not test_pass:\n",
    "            raise Exception(\"Test failed for profile '%s'. Addition masks have changed.\" % profile.name)\n",
    "\n",
    "        # Not testing histograms, halos subtraction coarse, halo addition field, halos removed field, stacked halo field, virial radii, halo masses.\n",
    "\n",
    "        if not test_pass:\n",
    "            raise Exception(\"Test failed for profile '%s'\" % profile.name)\n",
    "\n",
    "if REWRITE_BASELINES:\n",
    "    print(\"New regression test baselines written. Please set REWRITE_BASELINES to False now.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the convolution code handles empty mass bins correctly\n",
    "from testutils import *\n",
    "from cgmbrush import *\n",
    "REWRITE_BASELINES = False\n",
    "filename_header = \"baseline_e2e_emptybins\"\n",
    "profile = SphericalTophatProfile()\n",
    "\n",
    "min_mass = 1E13\n",
    "max_mass = 1E17 # making it large so we get empty bins\n",
    "log_bins = 10\n",
    "provider = BolshoiProvider()\n",
    "df, bins = create_halo_array_for_convolution(provider.get_halos(0), min_mass, max_mass, log_bins)\n",
    "print(bins)\n",
    "assert len(bins) == log_bins, \"{} bins were requested, got {}\".format(log_bins, len(bins))\n",
    "\n",
    "config = Configuration(profile, 1, resolution=1, provider=provider)\n",
    "config.min_mass = min_mass\n",
    "config.max_mass = max_mass\n",
    "config.log_bins = log_bins\n",
    "\n",
    "config.run()\n",
    "check_validity(config)\n",
    "\n",
    "if REWRITE_BASELINES:\n",
    "    saveResults(filename_header, **config.results, folder=TEST_DIR)\n",
    "else:\n",
    "    baseline = force_load_npz(filename_header, folder=TEST_DIR)\n",
    "\n",
    "    # Most important: test the final density grid values\n",
    "    for i in range(len(config.RS_array)):\n",
    "        test_pass = np.allclose(config.get_final_field()[i], baseline['final_density_field'][i], rtol=1e-12, atol=1e-3)\n",
    "        if not test_pass:\n",
    "            plot_grid_comparison(config.get_final_field()[i], baseline['final_density_field'][i])\n",
    "            raise Exception(\"Test failed for profile '{}'. Final density grid has changed at redshift {}.\".format(profile.name, config.RS_array[i]))\n",
    "    \n",
    "    # Test all the addition masks across all mass bins\n",
    "    test_pass = np.allclose(config.get_addition_masks(), baseline['add_masks'], rtol=1e-12, atol=1e-3)\n",
    "    if not test_pass:\n",
    "        raise Exception(\"Test failed for profile '%s'. Addition masks have changed.\" % profile.name)\n",
    "\n",
    "    # Not testing histograms, halos subtraction coarse, halo addition field, halos removed field, stacked halo field, virial radii, halo masses.\n",
    "\n",
    "    if not test_pass:\n",
    "        raise Exception(\"Test failed for profile '%s'\" % profile.name)\n",
    "\n",
    "if REWRITE_BASELINES:\n",
    "    print(\"New regression test baselines written. Please set REWRITE_BASELINES to False now.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Testing for make_halo_DM_map\n",
    "# This is the best baselining test for seeing if the CGM profiles are generating different masks than before; it's faster than the e2e one\n",
    "\n",
    "REWRITE_BASELINES = False\n",
    "filename_header = \"baseline_add_%s\"\n",
    "\n",
    "provider = BolshoiProvider()\n",
    "halos = provider.get_halos(0).head(80)\n",
    "df, bins = create_halo_array_for_convolution(halos, 1E9, 10**(15), 4)\n",
    "profiles = [TophatProfile(), SphericalTophatProfile(), NFWProfile(), FireProfile(), PrecipitationProfile(), MassDependentProfile(SphericalTophatProfile(rvir_factor=2), NFWProfile(), 1e11)]\n",
    "\n",
    "for profile in profiles:\n",
    "    print(\"Profile: %s\" % profile.name)\n",
    "    resolution = 2\n",
    "    results = make_halo_DM_map(provider, df, resolution, bins, profile, 1, 0)\n",
    "\n",
    "    if REWRITE_BASELINES:\n",
    "        saveArray(filename_header % profile.name, *results, folder=TEST_DIR)\n",
    "    else:\n",
    "        baseline = loadArray(filename_header % profile.name, folder=TEST_DIR)\n",
    "        test_pass = [np.allclose(results[i], baseline[i], rtol=1e-10, atol=1e-3) for i in range(4)]\n",
    "\n",
    "        if not test_pass[0]: # zoom in on the region where the 80 chosen halos are\n",
    "            plot_grid_comparison(results[0][0:128, 0:128], baseline[0][0:128, 0:128])\n",
    "\n",
    "        if not test_pass[1]:\n",
    "            print(\"conv_rad changed.\")\n",
    "            print(\"New Result: {}\".format(results[1]))\n",
    "            print(\"Baseline: {}\".format(baseline[1]))\n",
    "\n",
    "        if not test_pass[2]:\n",
    "            print(\"Addition masks changed.\")\n",
    "            compare_mask_lists(results[2], baseline[2], resolution)\n",
    "\n",
    "        if not test_pass[3]:\n",
    "            print(\"Mvir_avg changed.\")\n",
    "            print(\"New Result: {}\".format(results[3]))\n",
    "            print(\"Baseline: {}\".format(baseline[3]))\n",
    "\n",
    "        if not all(test_pass):\n",
    "            print(test_pass)\n",
    "            raise Exception(\"Test failed for profile '%s'\" % profile.name)\n",
    "\n",
    "if REWRITE_BASELINES:\n",
    "    print(\"New regression test baselines written. Please set REWRITE_BASELINES to False now.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_halo_array_for_convolution and add_halos test\n",
    "# Test that when a bin is empty (repeated values in bins) the code works still.\n",
    "from cgmbrush import *\n",
    "\n",
    "provider = BolshoiProvider()\n",
    "halos = provider.get_halos(0).head(80)\n",
    "df, bins = create_halo_array_for_convolution(halos, 1E9, 10**(15), 4)\n",
    "print(\"Halos in use: %s \" % len(df))\n",
    "print(bins)\n",
    "assert len(bins) == 4, \"4 bins dividers (3 bins) were requested\"\n",
    "\n",
    "results = make_halo_DM_map(provider, df, 1, bins, TophatProfile(), 1, 0)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8, 8))\n",
    "pos = ax.imshow(results[0][0:80, 0:80])\n",
    "fig.colorbar(pos, ax=ax)\n",
    "# No errors or warnings = pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract Halos Regression Tests\n",
    "from cgmbrush import *\n",
    "import numpy as np\n",
    "\n",
    "REWRITE_BASELINES = False\n",
    "filename_header = \"baseline_subtract_%s\"\n",
    "\n",
    "provider = BolshoiProvider()\n",
    "halos = provider.get_halos(0)\n",
    "df, bins = create_halo_array_for_convolution(halos, 1E10, 10**(15), 30)\n",
    "profiles = [ TophatProfile(), SphericalTophatProfile(), NFWProfile() ]\n",
    "\n",
    "for profile in profiles:\n",
    "    print(\"Profile: %s\" % profile.name)\n",
    "    scaling_radius = 1\n",
    "    redshift = 0\n",
    "    results = subtract_halos(provider, df, bins, profile, scaling_radius, redshift, halo)\n",
    "\n",
    "    if REWRITE_BASELINES:\n",
    "        saveArray(filename_header % profile.name, results, folder=TEST_DIR)\n",
    "    else:\n",
    "        baseline = loadArray(filename_header % profile.name, folder=TEST_DIR)\n",
    "        test_pass = np.allclose(results, baseline, rtol=1e-15, atol=1e-1)\n",
    "\n",
    "        if not test_pass:\n",
    "            plot_grid_comparison(results, baseline)\n",
    "            raise Exception(\"Test failed for profile '%s'\" % profile.name)\n",
    "\n",
    "if REWRITE_BASELINES:\n",
    "    print(\"New regression test baselines written. Please set REWRITE_BASELINES to False now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Testing for multiple redshifts stacking code\n",
    "# Requires 3 different density files to run\n",
    "REWRITE_BASELINES = False\n",
    "filename_header = \"baseline_stacking\"\n",
    "provider=BolshoiProvider()\n",
    "RS_array = RS_array_gen(1, provider.Lbox)[0:3]\n",
    "config = Configuration(SphericalTophatProfile(), 1, resolution=1, provider=provider, RS_array=RS_array)\n",
    "config.seed = 'test seed ensures random numbers generated the same way'\n",
    "config.min_mass = 10**10\n",
    "config.max_mass = 9*10**15\n",
    "config.log_bins = 30\n",
    "config.run(load_from_files=False) # don't mind loading cached version for this part for this test\n",
    "check_validity(config)\n",
    "\n",
    "config.generate_stacked_fields() # want to always run the stacked generation\n",
    "check_stacked_validity(config) \n",
    "\n",
    "if REWRITE_BASELINES:\n",
    "        stacked_fields = { 'stacked_orig_field': config.stacked_orig_field, 'stacked_removed_field': config.stacked_removed_field, 'stacked_addition_field': config.stacked_addition_field, 'stacked_final_field': config.stacked_final_field }\n",
    "        saveResults(filename_header, **stacked_fields, folder=TEST_DIR)\n",
    "else:\n",
    "    baseline = force_load_npz(filename_header, folder=TEST_DIR)\n",
    "\n",
    "    test_pass = np.allclose(config.get_stacked_orig_field(), baseline['stacked_orig_field'], rtol=1e-12, atol=1e-3)\n",
    "    if not test_pass:\n",
    "        plot_grid_comparison_delta(sum(config.get_stacked_orig_field()), sum(baseline['stacked_orig_field']))\n",
    "        raise Exception(\"Stacking test failed. Original density grid has changed.\")\n",
    "    \n",
    "    test_pass = np.allclose(config.get_stacked_removed_field(), baseline['stacked_removed_field'], rtol=1e-3, atol=1e-3)\n",
    "    if not test_pass:\n",
    "        plot_grid_comparison_delta(sum(config.get_stacked_removed_field()), sum(baseline['stacked_removed_field']))\n",
    "        raise Exception(\"Stacking test failed. Removed density grid has changed.\")\n",
    "    \n",
    "    test_pass = np.allclose(config.get_stacked_addition_field(), baseline['stacked_addition_field'], rtol=1e-3, atol=1e-3)\n",
    "    if not test_pass:\n",
    "        plot_grid_comparison_delta(sum(config.get_stacked_addition_field()), sum(baseline['stacked_addition_field']))\n",
    "        raise Exception(\"Stacking test failed. Additon density grid has changed.\")\n",
    "\n",
    "    test_pass = np.allclose(config.get_stacked_final_field(), baseline['stacked_final_field'], rtol=1e-3, atol=1e-3)\n",
    "    if not test_pass:\n",
    "        plot_grid_comparison_delta(sum(config.get_stacked_final_field()), sum(baseline['stacked_final_field']))\n",
    "        raise Exception(\"Stacking test failed. Final density grid has changed.\")\n",
    "\n",
    "if REWRITE_BASELINES:\n",
    "    print(\"New regression test baselines written. Please set REWRITE_BASELINES to False now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests getting halos from the BolshoiProvider. Will used cached versions. To test importing, delete your bol_halo_xxx.npy files from the var folder.\n",
    "p = BolshoiProvider()\n",
    "RS_values = RS_array_gen(1, p.Lbox)\n",
    "z0 = p.get_halos(0)\n",
    "zlow = p.get_halos(RS_values[0])\n",
    "zhigh = p.get_halos(RS_values[8])\n",
    "\n",
    "assert len(z0) == 8949374\n",
    "assert len(zlow) == 9328485\n",
    "assert len(zhigh) == 12847214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DM_vs_radius\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import convolve\n",
    "import matplotlib.pyplot as plt\n",
    "from testutils import *\n",
    "import pandas as pd\n",
    "import cgmbrush.plots.plotting_routines as makefig\n",
    "from cgmbrush.cgmbrush import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def add_cross(field, center_x, center_y, weight):\n",
    "    field[center_x][center_y] += weight\n",
    "    field[center_x - 1][center_y] += weight/3\n",
    "    field[center_x + 1][center_y] += weight/3\n",
    "    field[center_x][center_y - 1] += weight/3\n",
    "    field[center_x][center_y + 1] += weight/3\n",
    "\n",
    "def add_big_cross(field, center_x, center_y, weight):\n",
    "    field[center_x][center_y] += weight\n",
    "    field[center_x - 1][center_y] += weight/3\n",
    "    field[center_x + 1][center_y] += weight/3\n",
    "    field[center_x][center_y - 1] += weight/3\n",
    "    field[center_x][center_y + 1] += weight/3\n",
    "    field[center_x - 2][center_y] += weight/10\n",
    "    field[center_x + 2][center_y] += weight/10\n",
    "    field[center_x][center_y - 2] += weight/10\n",
    "    field[center_x][center_y + 2] += weight/10\n",
    "    field[center_x + 1][center_y + 1] += weight/10\n",
    "    field[center_x - 1][center_y + 1] += weight/10\n",
    "    field[center_x + 1][center_y - 1] += weight/10\n",
    "    field[center_x - 1][center_y - 1] += weight/10\n",
    "\n",
    "class FakeProvider(SimulationProvider): \n",
    "\n",
    "    Lbox = 50 / cosmo.h # 50 Mpc/h fake box\n",
    "    halofieldresolution = 50 # unlike bolshoi making this match the original density field size\n",
    "    \n",
    "    def get_density_field(self, redshift: float, resolution: int):\n",
    "        return np.zeros((50,50)) # 50 x 50 cell original grid\n",
    "\n",
    "    def get_halos(self, redshift : int) -> pd.DataFrame:\n",
    "        d = {'x': [3,15,13,30,30], 'y': [3,10,13,37,40], 'Mvir': [10**12, 10**12, 10**12, 10**12, 10**13]} # x,y coords are in Mpc/h like Bolshoi\n",
    "        df = pd.DataFrame(data=d)\n",
    "        return df\n",
    "\n",
    "    def get_z_name(redshift: float) -> str:\n",
    "        \"\"\"Gets the shorthand name associated with a given redshift, used in filenames.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "#df, bin_markers = create_halo_array_for_convolution(df, 10**11.5, 10**13.1, 3)\n",
    "#print(bin_markers)\n",
    "bin_markers = [0,4,5] \n",
    "crop_dim = 6\n",
    "provider = FakeProvider()\n",
    "df = provider.get_halos(0)\n",
    "field = provider.get_density_field(0, 1) \n",
    "\n",
    "# faked final density field\n",
    "add_cross(field, df['x'][0], df['y'][0], 300) \n",
    "add_cross(field, df['x'][1], df['y'][1], 300)\n",
    "add_cross(field, df['x'][2], df['y'][2], 300)\n",
    "add_cross(field, df['x'][3], df['y'][3], 300)\n",
    "add_big_cross(field, df['x'][4], df['y'][4], 900)\n",
    "\n",
    "plt.imshow(field) \n",
    "\n",
    "arr, DM_mass_bin = DM_vs_radius(field, df, crop_dim, bin_markers, provider)\n",
    "#print(DM_mass_bin)\n",
    "\n",
    "assert np.all(np.allclose(arr[0], [300, 53.75, 85/6, 40/3, 0])), \"Actual result was {}\".format(arr[0])\n",
    "assert np.all(np.allclose(arr[1], [900, 195, 28.75, 50, 0])), \"Actual result was {}\".format(arr[1])\n",
    "# If we didn't drop halos near the edge I'd expect this\n",
    "#assert np.all(np.equal(arr[0], [300, 52.8125, 10.625, 10, 0])), \"Actual result was {}\".format(arr[0])\n",
    "\n",
    "series = [(arr, [], 'Test', 'green')]\n",
    "makefig.make_DM_vs_Rad_profiles_plots(series, False, False, 500, 7000, 1, 50, [0,1], None, provider, [10**12, 10**13], [300, 900])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "843b3ea64dadd33c63cc6aae2bb10056a6a5bb9586b23146cad289d9c76c9a50"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
